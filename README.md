# QSum-using-Llama-2-7b
In this study, we introduced novel approach for automated text summarization of Quora answer posts, employing both transformer and baseline models. Our findings reveal that for Extractive summarization, K-Clustering outperforms all other models and Llama-2-7b performed better than other transformer models such as BART and BERT. 

This work furthers the development of automatic summarising methods and can improve the way information is retrieved from online communities such as Quora.

